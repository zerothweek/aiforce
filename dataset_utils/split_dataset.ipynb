{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def split_dataset(src_dir, dst_dir, split_config_file, make_valid=True, seed=42, version=\"main\"):\n",
    "    \"\"\"Split the dataset into train and valid directories based on case type ratios.\"\"\"\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Define directories\n",
    "    images_dir = os.path.join(src_dir, 'images')\n",
    "    labels_dir = os.path.join(src_dir, 'labels')\n",
    "\n",
    "    # Load split configuration from JSON file\n",
    "    with open(split_config_file, 'r', encoding='utf-8') as f:\n",
    "        split_config = json.load(f)\n",
    "\n",
    "    # Prepare the directories for split\n",
    "    train_images_dir = Path(dst_dir) / f\"train_{version}\" / \"images\"\n",
    "    valid_images_dir = Path(dst_dir) / f\"valid_{version}\" / \"images\"\n",
    "    train_labels_dir = Path(dst_dir) / f\"train_{version}\" / \"labels\"\n",
    "    valid_labels_dir = Path(dst_dir) / f\"valid_{version}\" / \"labels\"\n",
    "\n",
    "    # Create the directories if they don't exist\n",
    "    for dir_path in [train_images_dir, valid_images_dir, train_labels_dir, valid_labels_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Dictionary to hold the file paths by case type\n",
    "    case_type_files = {key: {'images': [], 'labels': []} for key in split_config}\n",
    "\n",
    "    # Collect all files from images and labels directories\n",
    "    images = list(Path(images_dir).glob('*.jpg'))\n",
    "    labels = list(Path(labels_dir).glob('*.txt'))\n",
    "\n",
    "    # Group files by case type based on the name prefix\n",
    "    for image in images:\n",
    "        for case_type in split_config.keys():  # Iterate over all keys in split_config\n",
    "            if image.name.startswith(case_type):  # Check if the image name starts with the case_type\n",
    "                case_type_files[case_type]['images'].append(image)\n",
    "                break  # Once found, no need to check further case types\n",
    "\n",
    "    for label in labels:\n",
    "        for case_type in split_config.keys():  # Iterate over all keys in split_config\n",
    "            if label.name.startswith(case_type):  # Check if the label name starts with the case_type\n",
    "                case_type_files[case_type]['labels'].append(label)\n",
    "                break  # Once found, no need to check further case types\n",
    "\n",
    "    # Split each case type's files\n",
    "    for case_type, files in case_type_files.items():\n",
    "        ratio = split_config[case_type].get('ratio', 1)  # Default to 1 (all training, no validation)\n",
    "        image_files = files['images']\n",
    "        label_files = files['labels']\n",
    "\n",
    "        # Skip empty case types\n",
    "        if len(image_files) == 0 or len(label_files) == 0:\n",
    "            print(f\"Warning: No data for case type {case_type}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        if len(image_files) != len(label_files):\n",
    "            raise ValueError(f\"Mismatch between image and label files for case type: {case_type}\")\n",
    "        image_files.sort(key=lambda x: x.stem)  # Sort by the file name (without extension)\n",
    "        label_files.sort(key=lambda x: x.stem)\n",
    "        # Shuffle and split files randomly\n",
    "        combined = list(zip(image_files, label_files))\n",
    "        random.shuffle(combined)\n",
    "        image_files, label_files = zip(*combined)\n",
    "\n",
    "        # Determine split index\n",
    "        split_index = int(len(image_files) * ratio)\n",
    "\n",
    "        # Split into training and validation\n",
    "        train_images = image_files[:split_index]\n",
    "        valid_images = image_files[split_index:]\n",
    "        train_labels = label_files[:split_index]\n",
    "        valid_labels = label_files[split_index:]\n",
    "\n",
    "        # Move files to the corresponding directories\n",
    "        for train_image, train_label in zip(train_images, train_labels):\n",
    "            shutil.copy(train_image, train_images_dir / train_image.name)\n",
    "            shutil.copy(train_label, train_labels_dir / train_label.name)\n",
    "\n",
    "        if make_valid:\n",
    "            for valid_image, valid_label in zip(valid_images, valid_labels):\n",
    "                shutil.copy(valid_image, valid_images_dir / valid_image.name)\n",
    "                shutil.copy(valid_label, valid_labels_dir / valid_label.name)\n",
    "\n",
    "    print(f\"Data split into {train_images_dir} and {valid_images_dir if make_valid else 'no valid set'}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roboflow project -> train_main, valid_main\n",
    "\n",
    "split_dataset(src_dir='/Users/jjookim/Projects/AIForce/datasets/final_dataset/train',\\\n",
    "              dst_dir='/Users/jjookim/Projects/AIForce/datasets/all_data',\\\n",
    "              split_config_file = '/Users/jjookim/Projects/AIForce/datasets/jsons/all_data.json',\\\n",
    "              make_valid=True, seed=42, version=\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_main -> train_v#\n",
    "\n",
    "split_dataset(src_dir='/Users/jjookim/Projects/AIForce/datasets/all_data/train_main',\\\n",
    "              dst_dir='/Users/jjookim/Projects/AIForce/datasets/all_data',\\\n",
    "              split_config_file = '/Users/jjookim/Projects/AIForce/datasets/jsons/train_v1.json',\\\n",
    "              make_valid=False, seed=42, version=\"v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_main -> valid_v#\n",
    "# Warning: need to change the file process after using this\n",
    "split_dataset(src_dir='/Users/jjookim/Projects/AIForce/datasets/all_data/train_main',\\\n",
    "              dst_dir='/Users/jjookim/Projects/AIForce/datasets/all_data',\\\n",
    "              split_config_file = '/Users/jjookim/Projects/AIForce/datasets/jsons/train_v1.json',\\\n",
    "              make_valid=False, seed=42, version=\"version name should be complicated and the train is the using valid in this case think brother\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maicon_study",
   "language": "python",
   "name": "maicon_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
